import random as rand
import itertools as iter

import logging
from eliot import start_action, log_call

import numpy as np
import random
from wepy.resampling.resamplers.resampler import Resampler
from wepy.resampling.resamplers.clone_merge  import CloneMergeResampler
from wepy.resampling.decisions.clone_merge import MultiCloneMergeDecision
from cowera.file_resampler import update_dcd_files

class CoWERAResampler(CloneMergeResampler):
    r"""

    Resampler implementing the new REVO algorithm.

    """

    # fields for resampler data
    RESAMPLING_FIELDS = CloneMergeResampler.RESAMPLING_FIELDS
    RESAMPLING_SHAPES = CloneMergeResampler.RESAMPLING_SHAPES #+ (Ellipsis,)
    RESAMPLING_DTYPES = CloneMergeResampler.RESAMPLING_DTYPES #+ (np.int,)


    # fields that can be used for a table like representation
    RESAMPLING_RECORD_FIELDS = CloneMergeResampler.RESAMPLING_RECORD_FIELDS

    # fields for resampling data
    RESAMPLER_FIELDS = CloneMergeResampler.RESAMPLER_FIELDS + \
                       ('num_walkers', 'distance_array', 'variation', 'image_shape', 'images')
    RESAMPLER_SHAPES = CloneMergeResampler.RESAMPLER_SHAPES + \
                       ((1,), Ellipsis, (1,), Ellipsis, Ellipsis)
    RESAMPLER_DTYPES = CloneMergeResampler.RESAMPLER_DTYPES + \
                       (int, float, float, int, None)

    # fields that can be used for a table like representation
    RESAMPLER_RECORD_FIELDS = CloneMergeResampler.RESAMPLER_RECORD_FIELDS + \
                              ('variation',)


    def __init__(self,
                 distance=None,
                 run_id=None,
                 merge_dist=None,
                 pmax=0.25,
                 pmin=1e-12,
                 init_state=None,
                 seed=None,
                 info_file_path=None,
                 increment = None,
                 dcd_folder = None,
                 n_d = None,
                 mode = "greedy",
                 **kwargs):

        """Constructor for the REVO Resampler.

        Parameters
        ----------


        distance : object implementing Distance
            The distance metric to compare walkers.

        merge_dist : float
            The merge distance threshold. Units should be the same as
            the distance metric.

        init_state : WalkerState object
            Used for automatically determining the state image shape.

        seed : None or int, optional
            The random seed. If None, the system (random) one will be used.

        """

        # call the init methods in the CloneMergeResampler
        # superclass. We set the min and max number of walkers to be
        # constant
        super().__init__(pmin=pmin, pmax=pmax,
                         min_num_walkers=Ellipsis,
                         max_num_walkers=Ellipsis,
                         mode=mode,
                         **kwargs)

        assert distance is not None,  "Distance object must be given."
        assert init_state is not None,  "An  state must be given."

        # Directory

        self.info_file_path = info_file_path

        # the distance metric

        self.distance = distance

        # merge distance

        self.merge_dist = merge_dist

        # run index

        self.run_id = run_id

        # direction

        self.increment = increment

        # number of data per sement

        self.n_d = n_d

        # setting the random seed
        self.seed = seed

        self.mode = mode

        #dcd folder
        self.dcd_folder = dcd_folder
        if seed is not None:
            rand.seed(seed)

        # we do not know the shape and dtype of the images until
        # runtime so we determine them here
        #print("init state",init_state)
        image = self.distance.get_proj_coord(init_state)
        self.image_dtype = image.dtype

        #print(self.pmax)

    def resampler_field_dtypes(self):
        """ Finds out the datatype of the image.

        Returns
        -------
        datatypes : tuple of datatype
        The type of reasampler image.

        """

        # index of the image idx
        image_idx = self.resampler_field_names().index('images')

        # dtypes adding the image dtype
        dtypes = list(super().resampler_field_dtypes())
        dtypes[image_idx] = self.image_dtype

        return tuple(dtypes)


    def _calcvariation(self, num_walker_copies, distance_arr,walker_weights):

        # calculate  walker variation values

        walker_variations = distance_arr.copy() #* walker_weights
        variation = np.sum(distance_arr * num_walker_copies * walker_weights)

        return variation, walker_variations

    def decide(self, walker_weights, num_walker_copies, distance_arr, distance_matrix, images):
        """
        Optimize trajectory variation by resampling walkers efficiently.
        """
        num_walkers = len(walker_weights)

        variations = []
        merge_groups = [[] for _ in range(num_walkers)]
        walker_clone_nums = np.zeros(num_walkers, dtype=int)

        new_walker_weights = np.array(walker_weights)
        new_num_walker_copies = np.array(num_walker_copies)
        distance_matrix = np.array(distance_matrix)
        # Precompute merge eligibility matrix
        merge_mask = distance_matrix <= self.merge_dist

        variation, walker_variations = self._calcvariation(new_num_walker_copies, distance_arr, walker_weights)
        variations.append(variation)

        productive = True
        while productive:
            productive = False

            # Candidate for cloning
            max_candidates = [
                (walker_variations[i], i)
                for i in range(num_walkers)
                if new_num_walker_copies[i] >= 1 and
                (new_walker_weights[i] / (new_num_walker_copies[i] + 1) > self.pmin) and
                len(merge_groups[i]) == 0
            ]
            max_idx = max(max_candidates)[1] if max_candidates else None

            # Candidate for merging
            # min_candidates = [
            #     (images[i], i)
            #     for i in range(num_walkers)
            #     if new_num_walker_copies[i] == 1 and
            #     new_walker_weights[i] < self.pmax and
            #     merge_mask[i].any()
            # ]
            # min_idx = min(min_candidates)[1] if min_candidates else None

            min_candidates = [
                                (walker_variations[i], i)
                                for i in range(num_walkers)
                                if new_num_walker_copies[i] == 1
                                and (new_walker_weights[i] < self.pmax)
                            ]

            min_idx = min(min_candidates)[1] if min_candidates else None

            closewalk = None
            happen = False
            if min_idx is not None and max_idx is not None and min_idx != max_idx:
                # Vectorized candidate selection
                candidates = np.where(
                    (new_num_walker_copies == 1) &
                    (np.arange(num_walkers) != min_idx) &
                    (np.arange(num_walkers) != max_idx) &
                    ((new_walker_weights + new_walker_weights[min_idx]) < self.pmax)
                )[0]

                eligible = candidates[merge_mask[min_idx, candidates]]
                if len(eligible) > 0:
                    closewalk = random.choice(eligible)

            #print(f"Max idx: {max_idx}, Max var: {walker_variations[max_idx] if max_idx is not None else 'N/A'}, Min idx: {min_idx}, Min var: {walker_variations[min_idx] if min_idx is not None else 'N/A'}, Close walk: {closewalk}, min dist : {distance_matrix[min_idx, closewalk] if closewalk is not None else 'N/A'}")
            if min_idx is not None and max_idx is not None and closewalk is not None:
                # r = np.random.uniform(0, new_walker_weights[closewalk] + new_walker_weights[min_idx])
                # if r < new_walker_weights[closewalk]:
                #     keep_idx, squash_idx = closewalk, min_idx
                # else:
                #     keep_idx, squash_idx = min_idx, closewalk
                keep_idx = closewalk
                squash_idx = min_idx

                new_num_walker_copies[squash_idx] = 0
                new_num_walker_copies[keep_idx] = 1
                new_num_walker_copies[max_idx] += 1

                new_variation, walker_variations = self._calcvariation(new_num_walker_copies, distance_arr, new_walker_weights)
                if self.mode == "greedy":
                    if new_variation > variation: # resampling is possible with these choices of walkers
                        variations.append(new_variation)

                        logging.info("Variance move to {} accepted".format(new_variation))

                        productive = True
                        variation = new_variation

                        # update weight
                        new_walker_weights[keep_idx] += new_walker_weights[squash_idx]
                        new_walker_weights[squash_idx] = 0.0

                        # add the squash index to the merge group
                        merge_groups[keep_idx].append(squash_idx)

                        # add the indices of the walkers that were already
                        # in the merge group that was just squashed
                        merge_groups[keep_idx].extend(merge_groups[squash_idx])

                        # reset the merge group that was just squashed to empty
                        merge_groups[squash_idx] = []

                        # increase the number of clones that the cloned
                        # walker has
                        walker_clone_nums[max_idx] += 1

                        logging.info("variance after selection: {}".format(new_variation))


                    # if not productive
                    else:
                        new_num_walker_copies[min_idx] = 1
                        new_num_walker_copies[closewalk] = 1
                        new_num_walker_copies[max_idx] -= 1


                elif self.mode == "probabilistic":
                    prob = new_variation / (new_variation + variation)
                    if random.random() < prob:
                        variations.append(new_variation)
                        productive = True
                        variation = new_variation

                        new_walker_weights[keep_idx] += new_walker_weights[squash_idx]
                        new_walker_weights[squash_idx] = 0.0

                        merge_groups[keep_idx].append(squash_idx)
                        merge_groups[keep_idx].extend(merge_groups[squash_idx])
                        merge_groups[squash_idx] = []

                        walker_clone_nums[max_idx] += 1

                    else:
                        # revert changes if unproductive
                        new_num_walker_copies[min_idx] = 1
                        new_num_walker_copies[closewalk] = 1
                        new_num_walker_copies[max_idx] -= 1



        if (variations[-1] > variations[0]):
            happen = True
        else:
            happen = False

        # given we know what we want to clone to specific slots
        # (squashing other walkers) we need to determine where these
        # squashed walkers will be merged
        walker_actions = self.assign_clones(merge_groups, walker_clone_nums)

        # because there is only one step in resampling here we just
        # add another field for the step as 0 and add the walker index
        # to its record as well
        for walker_idx, walker_record in enumerate(walker_actions):
            walker_record['step_idx'] = np.array([0])
            walker_record['walker_idx'] = np.array([walker_idx])


        return walker_actions, variations[-1], happen

    def get_dist(self, walkers, folder, n_d, it, n_bins, max_bins):

        # initialize arrays
        dl = np.zeros(len(walkers))
        dist_mat = np.zeros((len(walkers), len(walkers)))

        # make images for all the walker states
        images = []
        for walker in walkers:
            image = self.distance.get_proj_coord(walker.state)[0]
            images.append(image)
            #print(f"Image for walker: {image}")
        #print(f"Images for walkers: {images}")
        # get the combinations of indices for all walker pairs
        for i, j in iter.combinations(range(len(images)), 2):

            # calculate
            d12 = self.distance.image_distance(walkers[i].state, walkers[j].state)
            dist_mat[i][j] = d12
            dist_mat[j][i] = d12
            #print(f"Distance between walker {i} and {j}: {d12}")
        #print(f"Distance matrix: {dist_mat}")
        dl, n_bins = self.distance.intensity_calculation(n_walkers= len(walkers) ,path = folder,n_d = n_d, it = it, n_bins = n_bins,max_bins = max_bins)
        #print(f"Calculated distances: {dl}")
        #print(f"Number of bins: {n_bins}")
        return dl, [walker_dists for walker_dists in dist_mat], images , n_bins

    @log_call(include_args=[],
              include_result=False)

    def resample(self, walkers, cycle_id, n_bins, max_bins=125):
        """Resamples walkers based on REVO algorithm

        Parameters
        ----------
        walkers : list of walkers


        Returns
        -------
        resampled_walkers : list of resampled_walkers

        resampling_data : list of dict of str: value
            The resampling records resulting from the decisions.

        resampler_data :list of dict of str: value
            The resampler records resulting from the resampler actions.

        """

        #initialize the parameters
        num_walkers = len(walkers)
        walker_weights = [walker.weight for walker in walkers]
        num_walker_copies = [1 for i in range(num_walkers)]
        dcd_folder = self.dcd_folder
        cycle_id = cycle_id
        n_bins = n_bins
        max_bins = max_bins
        # calculate  distances
        distance_arr, distance_matrix, images, n_bins = self.get_dist(walkers,folder = dcd_folder , n_d = self.n_d, it = cycle_id,n_bins = n_bins,max_bins = max_bins)

        if self.increment == 1:
            # Closest walker distance
            cw_dist = np.max(images)
        else:
            cw_dist = np.min(images)

        # determine cloning and merging actions to be performed, by
        # maximizing the variation, i.e. the Decider
        resampling_data, variation, happen = self.decide(walker_weights, num_walker_copies, distance_arr, distance_matrix,images)


        file = open(f'{self.info_file_path}', 'a')
        file.write(f'Cycle: {cycle_id}'+'\t'+f'Clst walk. proj: {cw_dist}'+'\t'+f'Resampling happend: {happen}'+'\t'+f'n_bins: {n_bins}'+'\n')
        file.close()

        # convert the target idxs and decision_id to feature vector arrays
        for record in resampling_data:
            record['target_idxs'] = np.array(record['target_idxs'])
            record['decision_id'] = np.array([record['decision_id']])

        # update trajectory files according to the resampling data
        update_dcd_files(resampling_data, dcd_folder = dcd_folder)

        # actually do the cloning and merging of the walkers
        resampled_walkers = self.DECISION.action(walkers, [resampling_data])


        # flatten the distance matrix and give the number of walkers
        # as well for the resampler data, there is just one per cycle
        resampler_data = [{'distance_array' : distance_arr,
                           'num_walkers' : np.array([len(walkers)]),
                           'variation' : np.array([variation]),
                           'images' : np.ravel(np.array(images)),
                           'image_shape' : np.array(images[0].shape)}]

        return resampled_walkers, resampling_data, resampler_data, n_bins